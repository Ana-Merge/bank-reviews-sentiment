services:
  preprocess-data:
    build: .
    image: train-model-gpu
    volumes:
      - ../../../data/generated:/data/generated
      - ./results/logs:/app/logs
    command: python preprocess_common.py
    stdin_open: true
    tty: true
    profiles:
      - preprocess

  train-model:
    build: .
    image: train-model-gpu
    volumes:
      - ../../../data/generated/processed:/data
      - ./results/results_topics:/app/results_topics
      - ./results/results_sentiments:/app/results_sentiments
      - ./results/topic_model:/app/topic_model
      - ./results/sentiment_model:/app/sentiment_model
      - ./results/logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    command: python train_cat.py
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available()"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - train